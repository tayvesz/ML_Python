{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_v2.csv',sep=';',encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_v2.csv',sep=';',encoding='latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No records with identical Id\n",
    "len(df_train.Id.unique()) == len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    10000\n",
       "Title                  9999\n",
       "FullDescription       10000\n",
       "LocationNormalized    10000\n",
       "ContractType           3556\n",
       "ContractTime           4737\n",
       "Company                5951\n",
       "Category              10000\n",
       "SalaryNormalized      10000\n",
       "SourceName            10000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No records with identical Id\n",
    "len(df_test.Id.unique()) == len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                    5000\n",
       "Title                 5000\n",
       "FullDescription       5000\n",
       "LocationNormalized    5000\n",
       "ContractType           808\n",
       "ContractTime          4188\n",
       "Company               4709\n",
       "Category              5000\n",
       "SourceName            5000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "Id                    10000 non-null int64\n",
      "Title                 9999 non-null object\n",
      "FullDescription       10000 non-null object\n",
      "LocationNormalized    10000 non-null object\n",
      "ContractType          3556 non-null object\n",
      "ContractTime          4737 non-null object\n",
      "Company               5951 non-null object\n",
      "Category              10000 non-null object\n",
      "SalaryNormalized      10000 non-null int64\n",
      "SourceName            10000 non-null object\n",
      "dtypes: int64(2), object(8)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The FullDescription is the a kind of unformated concatenation of the other features ==> We will drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Engineering Systems Analyst Dorking Surrey Sal...\n",
      "1    Stress Engineer Glasgow Salary **** to **** We...\n",
      "Name: FullDescription, dtype: object \n",
      "\n",
      "0    Engineering Systems Analyst\n",
      "1        Stress Engineer Glasgow\n",
      "Name: Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_train.FullDescription.head(2),'\\n')\n",
    "print(df_train.Title.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 1. Drop Id, storing SalaryNormalized and FullDescription\n",
    "- Dropping Id which is useless for the prediction purpose\n",
    "- Storing the SalaryNormalized features which is the target feature (y)\n",
    "- Storing FullDescription, we will remove it from the training data because it is a unformatted merge of the other features\n",
    "- Storing the Id of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_descript_tr = df_train.FullDescription\n",
    "Salary = df_train.SalaryNormalized\n",
    "SalaryLog = np.log(Salary)\n",
    "df_train.drop(['Id','FullDescription','SalaryNormalized'],axis=1,inplace=True)\n",
    "test_Id = df_test.Id\n",
    "df_test.drop(['Id','FullDescription'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merging the test and train data \n",
    "- Let us merge the training and test data in to a global dataframe **df**\n",
    "- Hence, we will get the same levels for binning and dummyfication purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 7 columns):\n",
      "Title                 14999 non-null object\n",
      "LocationNormalized    15000 non-null object\n",
      "ContractType          4364 non-null object\n",
      "ContractTime          8925 non-null object\n",
      "Company               10660 non-null object\n",
      "Category              15000 non-null object\n",
      "SourceName            15000 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 820.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_train,df_test],axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can observe that there are some missing values on the following features:**\n",
    "- Title\n",
    "- ContractType\n",
    "- ContractTime\n",
    "- Company"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. Title Feature\n",
    "- Only one missing value: Index 1588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1588"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_missing_index = df[df.Title.isnull()].index[0]\n",
    "title_missing_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                                       NaN\n",
       "LocationNormalized                    Liverpool\n",
       "ContractType                          full_time\n",
       "ContractTime                                NaN\n",
       "Company                                     NaN\n",
       "Category              Healthcare & Nursing Jobs\n",
       "SourceName                       careworx.co.uk\n",
       "Name: 1588, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[title_missing_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quality Improvement Manager North West England Specialist Services ****  **** Our client, a leading provider of Supported Living and Residential Services across the UK require a Quality Improvement Manager for the North West. The successful candidate will provide a consistent and systematic approach to improve outcomes, service user experience and safety in all services across the business. This will require delivering quality standards that comply with and exceed those specified by statutory, regulatory bodies and contractual requirements. The salary on offer is ****  **** For more information or to apply please call Dave Langford at Compass Associates on **** **** **** or email dlangfordcompassltd.co.uk'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_descript_missing_title = full_descript_tr[title_missing_index]\n",
    "full_descript_missing_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** As seen previously the first words of FullDescription feature corresponds usually the \"Title\", hence we will replace the missing data by the three first words of the full description. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quality Improvement Manager'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_words = full_descript_missing_title.split(' ')[:3]\n",
    "missing_title = ' '.join(title_words)\n",
    "missing_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[title_missing_index,'Title'] = missing_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 7 columns):\n",
      "Title                 15000 non-null object\n",
      "LocationNormalized    15000 non-null object\n",
      "ContractType          4364 non-null object\n",
      "ContractTime          8925 non-null object\n",
      "Company               10660 non-null object\n",
      "Category              15000 non-null object\n",
      "SourceName            15000 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 820.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Bag of words of titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Checking the number of levels of the Title feature (different titles) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12052\n"
     ]
    }
   ],
   "source": [
    "print(len(df.Title.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are two many levels. So let us create a Bag of words of this features.\n",
    "- Indeed, this strategy could also be applied to the FullDescription features, however we decided to apply to the Title feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_bag_of_words = [i for i in df.Title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "letters_only = [ re.sub(\"[^a-zA-Z]\", \" \", w ).strip() for w in title_bag_of_words]\n",
    "lower_case = [l.lower().strip() for l in letters_only]\n",
    "title_bag_of_words = [re.sub(' +',' ',l) for l in lower_case] # remove extra blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['engineering systems analyst',\n",
       " 'stress engineer glasgow',\n",
       " 'modelling and simulation analyst',\n",
       " 'engineering systems analyst mathematical modeller',\n",
       " 'pioneer miser engineering systems analyst']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_bag_of_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa rosette</th>\n",
       "      <th>aberdeen</th>\n",
       "      <th>account</th>\n",
       "      <th>account director</th>\n",
       "      <th>account executive</th>\n",
       "      <th>account handler</th>\n",
       "      <th>account manager</th>\n",
       "      <th>accountant</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>worker jobs</th>\n",
       "      <th>workers</th>\n",
       "      <th>workshop</th>\n",
       "      <th>writer</th>\n",
       "      <th>year</th>\n",
       "      <th>year primary</th>\n",
       "      <th>year primary teacher</th>\n",
       "      <th>year teacher</th>\n",
       "      <th>years</th>\n",
       "      <th>yorkshire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 1200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aa rosette  aberdeen  account  account director  account executive  \\\n",
       "0  0.0         0.0       0.0      0.0               0.0                0.0   \n",
       "1  0.0         0.0       0.0      0.0               0.0                0.0   \n",
       "2  0.0         0.0       0.0      0.0               0.0                0.0   \n",
       "\n",
       "   account handler  account manager  accountant  accounts    ...      \\\n",
       "0              0.0              0.0         0.0       0.0    ...       \n",
       "1              0.0              0.0         0.0       0.0    ...       \n",
       "2              0.0              0.0         0.0       0.0    ...       \n",
       "\n",
       "   worker jobs  workers  workshop  writer  year  year primary  \\\n",
       "0          0.0      0.0       0.0     0.0   0.0           0.0   \n",
       "1          0.0      0.0       0.0     0.0   0.0           0.0   \n",
       "2          0.0      0.0       0.0     0.0   0.0           0.0   \n",
       "\n",
       "   year primary teacher  year teacher  years  yorkshire  \n",
       "0                   0.0           0.0    0.0        0.0  \n",
       "1                   0.0           0.0    0.0        0.0  \n",
       "2                   0.0           0.0    0.0        0.0  \n",
       "\n",
       "[3 rows x 1200 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "ngramrange = (1,5) # The range of the N-grams\n",
    "\n",
    "M_feat = 1200 # Maximal number of features, this is actually a tunning parameter\n",
    "tfidf_transformer = TfidfVectorizer(lowercase=True, \n",
    "                                    max_features = M_feat, \n",
    "                                    stop_words='english', \n",
    "                                    ngram_range=ngramrange)\n",
    "\n",
    "tfidf_transformer.fit(title_bag_of_words)\n",
    "\n",
    "tfidf_df = tfidf_transformer.transform(title_bag_of_words)\n",
    "tfidf_df = tfidf_df.toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_df)\n",
    "\n",
    "tfidf_df.columns = tfidf_transformer.get_feature_names()\n",
    "tfidf_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSA\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# N_Components = 50\n",
    "# svd = TruncatedSVD(N_Components)\n",
    "# normalizer = Normalizer(copy=False)\n",
    "# lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "# tfidf_df = lsa.fit_transform(tfidf_df)\n",
    "# tfidf_df = pd.DataFrame(tfidf_df)\n",
    "# column_topic = ['c'+str(i) for i in range(N_Components)]\n",
    "# tfidf_df.column_topic = column_topic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let us concatenate the tfidf dataframe to the initial dataframe and drop the column \"Title\" **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 1206)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df,tfidf_df],axis=1)\n",
    "df.drop('Title',axis=1,inplace=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Handling the missing values of ContractTypes,ContractTime and Company Features\n",
    "- Since, there are large number of missing values, we decided to not drop the corresponding rows\n",
    "- We have two options:\n",
    "    - just replace by the mode (categorical features)\n",
    "    - create a new category \"NotAvailable\" for the missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def handlingMissingData_Mode(df,column_name):\n",
    "    df[column_name].fillna(df[column_name].mode()[0], inplace=True)\n",
    "    return df\n",
    "\n",
    "def handlingMissingData_NotAv(df,column_name):\n",
    "    df[column_name].fillna('NotAvailable', inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Finally, we used the first technique of missing value imputation because we got better results with it **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_with_miss_val = ['ContractType','ContractTime','Company','Category']\n",
    "for c in columns_with_miss_val:\n",
    "    handlingMissingData_Mode(df,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Columns: 1206 entries, LocationNormalized to yorkshire\n",
      "dtypes: float64(1200), object(6)\n",
      "memory usage: 138.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Useful Functions\n",
    "### These functions will be used to re-encode the categorical features and to dummify them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**a) Function which re-encodes the values which are not in the top \"n\" to \"Else\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reEncodingValues(x,top_n):\n",
    "    if x not in top_n:\n",
    "        x = 'Else'\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** b) Function finding the \"n\" most frequent values in a data frame **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_n_values(df,c,n):\n",
    "    top_n_loc = df_train[c].value_counts()[:n]\n",
    "    top_n_loc = top_n_loc.keys().tolist()\n",
    "    return top_n_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Functions which dummifies the columns and drops the initial columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dummyFunction(df,c):\n",
    "    c_dummies = pd.get_dummies(df[c],prefix=c)\n",
    "    df = pd.concat([df, c_dummies], axis=1)\n",
    "    df_out = df.drop(c,axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. ContractType and ContratTime Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_time    14372\n",
      "part_time      628\n",
      "Name: ContractType, dtype: int64\n",
      "\n",
      "permanent    13717\n",
      "contract      1283\n",
      "Name: ContractTime, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.ContractType.value_counts())\n",
    "print()\n",
    "print(df.ContractTime.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** For these two features we used just a dummyfication **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_column = ['ContractType','ContractTime']\n",
    "for c in list_column:\n",
    "    df = dummyFunction(df,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Columns: 1208 entries, LocationNormalized to ContractTime_permanent\n",
      "dtypes: float64(1200), object(4), uint8(4)\n",
      "memory usage: 137.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Location Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of uniques values\n",
    "len(df.LocationNormalized.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UK                   2515\n",
       "London               1730\n",
       "Manchester            363\n",
       "The City              335\n",
       "Leeds                 298\n",
       "Belfast               240\n",
       "South East London     215\n",
       "Birmingham            202\n",
       "Surrey                182\n",
       "Bristol               171\n",
       "Name: LocationNormalized, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LocationNormalized.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UK',\n",
       " 'London',\n",
       " 'Manchester',\n",
       " 'Leeds',\n",
       " 'Belfast',\n",
       " 'Birmingham',\n",
       " 'The City',\n",
       " 'Surrey',\n",
       " 'Sheffield',\n",
       " 'Hampshire']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 10\n",
    "c = 'LocationNormalized'\n",
    "top_N_locations = top_n_values(df.LocationNormalized,c,N)\n",
    "top_N_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Dorking\n",
       "1      Glasgow\n",
       "2    Hampshire\n",
       "3       Surrey\n",
       "4       Surrey\n",
       "Name: LocationNormalized, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[c].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Else\n",
       "1         Else\n",
       "2    Hampshire\n",
       "3       Surrey\n",
       "4       Surrey\n",
       "Name: LocationNormalized, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[c] = df[c].apply(lambda x:reEncodingValues(x,top_N_locations)) \n",
    "df[c].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = dummyFunction(df,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Category, SourceName Company features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Healthcare & Nursing Jobs      3412\n",
       "IT Jobs                        2289\n",
       "Engineering Jobs               2163\n",
       "Accounting & Finance Jobs       999\n",
       "Sales Jobs                      811\n",
       "HR & Recruitment Jobs           727\n",
       "Hospitality & Catering Jobs     659\n",
       "Teaching Jobs                   549\n",
       "Other/General Jobs              431\n",
       "Customer Services Jobs          377\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Category.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "careworx.co.uk           2991\n",
       "jobsite.co.uk            2240\n",
       "MyUkJobs                 1559\n",
       "cv-library.co.uk         1110\n",
       "totaljobs.com             796\n",
       "theitjobboard.co.uk       643\n",
       "fish4.co.uk               441\n",
       "planetrecruit.com         436\n",
       "hays.co.uk                384\n",
       "thecareerengineer.com     312\n",
       "Name: SourceName, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.SourceName.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JOBG8                  4817\n",
       "Jobsite Jobs            282\n",
       "Fresh Partnership       262\n",
       "ARRAY                   222\n",
       "UKStaffsearch           197\n",
       "Chef Results            146\n",
       "Clear Selection         132\n",
       "Triumph Consultants      99\n",
       "JHR                      75\n",
       "Castle Recruitment       74\n",
       "Name: Company, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Company.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** According to the distribution of the different values and also based on CV results we will:**\n",
    "\n",
    "- take the **top 5 for Category**\n",
    "\n",
    "- **we will drop SourceName and Company features**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 5\n",
    "c = 'Category'\n",
    "top_N_Category = top_n_values(df,c,N)\n",
    "df[c] = df[c].apply(lambda x:reEncodingValues(x,top_N_Category)) \n",
    "df = dummyFunction(df,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. SourceName and Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#N = 4\n",
    "#c = 'SourceName'\n",
    "#top_N_Sources = top_n_values(df,c,N)\n",
    "#df[c] = df[c].apply(lambda x:reEncodingValues(x,top_N_Sources)) \n",
    "#df = dummyFunction(df,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#N = 7\n",
    "#c = 'Company'\n",
    "#top_N_Company = top_n_values(df,c,N)\n",
    "#df[c] = df[c].apply(lambda x:reEncodingValues(x,top_N_Company)) \n",
    "#df = dummyFunction(df,c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 8.3. Dropping SourceName and Company Features\n",
    "- Actually, we got some better results without these two features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "column_to_drop = ['Company','SourceName']\n",
    "df.drop(column_to_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yves/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/yves/anaconda3/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_train = len(df_train)\n",
    "size_test = len(df_test)\n",
    "print(size_train)\n",
    "size_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: (10000, 1221)\n",
      "test size: (5000, 1221)\n"
     ]
    }
   ],
   "source": [
    "train_data = df.loc[0:size_train-1,]\n",
    "test_data = df.loc[size_train:,]\n",
    "\n",
    "print('train size:',train_data.shape)\n",
    "print('test size:',test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, SalaryLog, test_size=0.3,  random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1.2 Grid search - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.1s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.9s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:   21.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "           max_features='sqrt', max_leaf_nodes=None,\n",
      "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "           min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=-1, oob_score=False, random_state=0,\n",
      "           verbose=1, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.20213626170820018"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(n_estimators=100, \n",
    "                                 bootstrap = True,\n",
    "                                 random_state=0,\n",
    "                                 verbose = 1,\n",
    "                                 n_jobs=-1)\n",
    "\n",
    "parameters = {'max_depth':[None],\n",
    "    'min_samples_split': [5,10,15],\n",
    "    'max_features': ['sqrt']\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(rf_model, \n",
    "                  parameters,\n",
    "                  cv=5,\n",
    "                  verbose=1,\n",
    "                    \n",
    "                  scoring='neg_mean_squared_error')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "rf_reg = clf.best_estimator_\n",
    "print(rf_reg)\n",
    "np.mean(abs(rf_reg.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Training on the global training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Let us train the best estimator with the entire training data set and using a larger number of trees (the higher the better in the case of Random Forest)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:   26.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:   45.7s\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 8434 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 9784 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 10000 out of 10000 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "rf_reg = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
    "           max_features='sqrt', max_leaf_nodes=None,\n",
    "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "           min_samples_split=5, min_weight_fraction_leaf=0.0,\n",
    "           n_estimators=10000, n_jobs=-1, oob_score=False, random_state=0,\n",
    "           verbose=1, warm_start=False).fit(train_data,SalaryLog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done 784 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=8)]: Done 1234 tasks      | elapsed:    0.9s\n",
      "[Parallel(n_jobs=8)]: Done 1784 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=8)]: Done 2434 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=8)]: Done 3184 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=8)]: Done 4034 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=8)]: Done 4984 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=8)]: Done 6034 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=8)]: Done 7184 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=8)]: Done 8434 tasks      | elapsed:    6.1s\n",
      "[Parallel(n_jobs=8)]: Done 9784 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=8)]: Done 10000 out of 10000 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred = rf_reg.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 29232.44201215,  34834.73884053,  48071.18564824, ...,\n",
       "        34434.07662364,  29670.81655565,  32258.34319432])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.exp(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf result_rf.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'Id':test_Id,'PredictedSalary':y_pred})\n",
    "result.to_csv('result_rf.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle score: 9546.54523\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. Features importance\n",
    "- Useful (features seletion tool) for further study "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "importances = rf_reg.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "std = np.std([tree.feature_importances_ for tree in rf_reg.estimators_],axis=0)\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.bar(range(test_data.shape[1]), importances[indices],color=\"k\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(train_data.shape[1]), train_data.columns[indices])\n",
    "plt.xlim([-1, train_data.shape[1]])\n",
    "ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=90)\n",
    "plt.title('Features importance')\n",
    "plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Actually we started directly by the Random Forest Regressor. However, we could start by a simpler model like LASSO. Hence, Let us experiment this regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1. Grid search - Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .............................................. alpha=1.0 - 1.0min\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .............................................. alpha=0.5 - 1.2min\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] .............................................. alpha=0.5 - 1.3min\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] .............................................. alpha=1.0 - 1.4min\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] ................................................ alpha=5 -   6.3s\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] ................................................ alpha=5 -   5.8s\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] .............................................. alpha=1.0 - 1.5min\n",
      "[CV] alpha=5 .........................................................\n",
      "[CV] ................................................ alpha=5 -   5.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of  15 | elapsed:  1.6min remaining:  1.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................................ alpha=5 -  11.7s\n",
      "[CV] ................................................ alpha=5 -  12.7s\n",
      "[CV] .............................................. alpha=0.5 - 1.7min\n",
      "[CV] .............................................. alpha=0.5 - 1.9min\n",
      "[CV] .............................................. alpha=1.0 -  51.0s\n",
      "[CV] .............................................. alpha=0.5 - 1.9min\n",
      "[CV] .............................................. alpha=1.0 -  44.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7566.371814228326"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import grid_search\n",
    "from sklearn.linear_model import Lasso\n",
    "parameters = {'alpha':[0.5,  1.0, 5]}\n",
    "\n",
    "model = Lasso(random_state=0) # we don't specify alpha directly, we'll specify multiple alphas to try below\n",
    "\n",
    "gs = grid_search.GridSearchCV( model, \n",
    "                                parameters,\n",
    "                                cv=5,\n",
    "                                verbose=2,\n",
    "                                scoring='neg_mean_absolute_error',\n",
    "                                n_jobs=-1)\n",
    "gs.fit(X_train, y_train)\n",
    "lasso_model = gs.best_estimator_\n",
    "np.mean(abs(lasso_model.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=0,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2. Train on the global training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let us train with the global train data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Lasso_final = Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=0,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False).fit(train_data,Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3. Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = Lasso_final.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm -rf result_lasso.csv\n",
    "result = pd.DataFrame({'Id':test_Id,'PredictedSalary':y_pred})\n",
    "result.to_csv('result_lasso.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Lasso = 9812.98369"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] max_depth=2, n_estimators=50 ....................................\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] max_depth=2, n_estimators=100 ...................................\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ........................... max_depth=2, n_estimators=50 -   9.4s\n",
      "[CV] max_depth=2, n_estimators=200 ...................................\n",
      "[CV] ........................... max_depth=2, n_estimators=50 -   9.8s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] ........................... max_depth=2, n_estimators=50 -  10.4s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=100 -  19.5s\n",
      "[CV] max_depth=2, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=100 -  23.3s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] .......................... max_depth=2, n_estimators=100 -  23.5s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] .......................... max_depth=2, n_estimators=200 -  57.2s\n",
      "[CV] max_depth=4, n_estimators=50 ....................................\n",
      "[CV] ........................... max_depth=4, n_estimators=50 -  34.3s\n",
      "[CV] ........................... max_depth=4, n_estimators=50 -  35.9s\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=200 - 1.0min\n",
      "[CV] max_depth=4, n_estimators=100 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=200 -  58.7s\n",
      "[CV] max_depth=4, n_estimators=200 ...................................\n",
      "[CV] ........................... max_depth=4, n_estimators=50 -  30.1s\n",
      "[CV] max_depth=4, n_estimators=200 ...................................\n",
      "[CV] .......................... max_depth=4, n_estimators=100 -  55.2s\n",
      "[CV] max_depth=4, n_estimators=200 ...................................\n",
      "[CV] .......................... max_depth=4, n_estimators=100 -  56.6s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=4, n_estimators=100 -  56.6s\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=500 - 2.4min\n",
      "[CV] max_depth=4, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=2, n_estimators=500 - 2.5min\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n",
      "[CV] .......................... max_depth=2, n_estimators=500 - 2.5min\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n",
      "[CV] .......................... max_depth=4, n_estimators=200 - 1.8min\n",
      "[CV] max_depth=6, n_estimators=50 ....................................\n",
      "[CV] .......................... max_depth=4, n_estimators=200 - 1.7min\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] ........................... max_depth=6, n_estimators=50 -  40.1s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] ........................... max_depth=6, n_estimators=50 -  37.8s\n",
      "[CV] max_depth=6, n_estimators=100 ...................................\n",
      "[CV] ........................... max_depth=6, n_estimators=50 -  36.3s\n",
      "[CV] max_depth=6, n_estimators=200 ...................................\n",
      "[CV] .......................... max_depth=4, n_estimators=200 - 1.7min\n",
      "[CV] max_depth=6, n_estimators=200 ...................................\n",
      "[CV] .......................... max_depth=6, n_estimators=100 - 1.2min\n",
      "[CV] max_depth=6, n_estimators=200 ...................................\n",
      "[CV] .......................... max_depth=6, n_estimators=100 - 1.3min\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=6, n_estimators=100 - 1.2min\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=6, n_estimators=200 - 2.4min\n",
      "[CV] max_depth=6, n_estimators=500 ...................................\n",
      "[CV] .......................... max_depth=6, n_estimators=200 - 2.6min\n",
      "[CV] .......................... max_depth=4, n_estimators=500 - 4.3min\n",
      "[CV] .......................... max_depth=4, n_estimators=500 - 4.4min\n",
      "[CV] .......................... max_depth=6, n_estimators=200 - 2.3min\n",
      "[CV] .......................... max_depth=4, n_estimators=500 - 4.2min\n",
      "[CV] .......................... max_depth=6, n_estimators=500 - 3.5min\n",
      "[CV] .......................... max_depth=6, n_estimators=500 - 3.7min\n",
      "[CV] .......................... max_depth=6, n_estimators=500 - 2.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  36 out of  36 | elapsed:  8.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.584089124131479, {'max_depth': 6, 'n_estimators': 500})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "clf = GridSearchCV(xgb_model,\n",
    "                   {'max_depth': [2,4,6],\n",
    "                    'n_estimators': [50,100,200,500]},\n",
    "                   n_jobs = -1,\n",
    "                   verbose=2)\n",
    "\n",
    "clf.fit(X_train,y_train)\n",
    "clf.best_score_, clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7107.593250325521"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgbreg = clf.best_estimator_\n",
    "print(xgbreg)\n",
    "np.mean(abs(xgbreg.predict(X_test)-y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbreg = xgb.XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=6,\n",
    "       min_child_weight=1, missing=None, n_estimators=500, nthread=-1,\n",
    "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1).fit(train_data,SalaryLog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = xgbreg.predict(test_data)\n",
    "result = pd.DataFrame({'Id':test_Id,'PredictedSalary':np.exp(y_pred)})\n",
    "result.to_csv('result_xgb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: 9339.03711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
